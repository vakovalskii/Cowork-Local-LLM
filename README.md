<div align="center">

# Agent Cowork - Local LLM Edition

[![Version](https://img.shields.io/badge/version-0.0.3-blue.svg)](https://github.com/vakovalskii/Cowork-Local-LLM/releases)
[![Platform](https://img.shields.io/badge/platform-%20Windows%20%7C%20macOS%20%7C%20Linux-lightgrey.svg)](https://github.com/vakovalskii/Cowork-Local-LLM)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

**Desktop AI Assistant with Local Model Support**

> ğŸ”± Forked from [DevAgentForge/Claude-Cowork](https://github.com/DevAgentForge/Claude-Cowork)  
> Reworked to support OpenAI SDK and local models (vLLM, Qwen, Llama)

</div>

---

## âœ¨ Features

- âœ… **OpenAI SDK** â€” full API control, compatible with any OpenAI-compatible endpoint
- âœ… **Local Models** â€” vLLM, Ollama, LM Studio support
- âœ… **Modular Tools** â€” each tool in separate file for easy maintenance
- âœ… **Web Search** â€” Tavily integration for internet search (optional)
- âœ… **Security** â€” directory sandboxing for safe file operations
- âœ… **Cross-platform** â€” Windows, macOS, Linux with proper shell commands
- âœ… **Modern UI** â€” React + Electron with auto-scroll and streaming

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/vakovalskii/Cowork-Local-LLM.git
cd Cowork-Local-LLM

# Install dependencies (use bun for faster install)
bun install
# or
npm install

# Compile Electron code
npm run transpile:electron
```

### Running in Development

```bash
# Start both Vite and Electron
npm run dev
```

Or manually in two terminals:

**Terminal 1 - React Dev Server:**
```bash
npm run dev:react
```

**Terminal 2 - Electron (after Vite starts):**
```bash
# macOS/Linux
NODE_ENV=development npx electron .

# Windows PowerShell
$env:NODE_ENV='development'; npx electron .
```

### Configuration

1. Click **Settings** (âš™ï¸) in the app
2. Configure your API:
   - **API Key** â€” your key (or `dummy-key` for local models)
   - **Base URL** â€” API endpoint
   - **Model Name** â€” model identifier
   - **Temperature** â€” 0.0-2.0 (default: 0.3)
   - **Tavily API Key** (optional) â€” for web search
3. Click **Save Settings**

### Example Configurations

**Local vLLM:**
```json
{
  "apiKey": "dummy-key",
  "baseUrl": "http://localhost:8000",
  "model": "qwen3-30b-a3b-instruct-2507",
  "temperature": 0.3
}
```

**Claude:**
```json
{
  "apiKey": "sk-ant-...",
  "baseUrl": "https://api.anthropic.com",
  "model": "claude-sonnet-4-20250514",
  "temperature": 0.3
}
```

**OpenAI:**
```json
{
  "apiKey": "sk-...",
  "baseUrl": "https://api.openai.com",
  "model": "gpt-4",
  "temperature": 0.3
}
```

## ğŸ¦™ Local Model Setup (vLLM)

```bash
vllm serve qwen3-30b-a3b-instruct-2507 \
  --port 8000 \
  --enable-auto-tool-choice \
  --tool-call-parser hermes
```

**Requirements:**
- OpenAI-compatible API (`/v1/chat/completions`)
- Function calling support
- Streaming support

## ğŸ› ï¸ Available Tools

### File Operations
- **Bash** â€” execute shell commands (PowerShell/bash)
- **Read** â€” read file contents
- **Write** â€” create new files
- **Edit** â€” modify files (search & replace)

### Search Tools
- **Glob** â€” find files by pattern
- **Grep** â€” search text in files

### Web Tools (Optional)
- **WebSearch** â€” search the web using Tavily API
- **ExtractPageContent** â€” extract full content from web pages

### User Interaction
- **AskUserQuestion** â€” ask user for clarification

> **Note:** Web tools require Tavily API key in Settings

## ğŸ“¦ Building

### macOS (DMG)
```bash
npm run dist:mac
```

### Windows (EXE)
```bash
npm run dist:win
```

### Linux (AppImage)
```bash
npm run dist:linux
```

## ğŸ—ï¸ Project Structure

```
src/
â”œâ”€â”€ electron/                    # Electron main process
â”‚   â”œâ”€â”€ main.ts                 # Entry point
â”‚   â”œâ”€â”€ ipc-handlers.ts         # IPC communication
â”‚   â””â”€â”€ libs/
â”‚       â”œâ”€â”€ runner-openai.ts    # OpenAI API runner
â”‚       â”œâ”€â”€ prompt-loader.ts    # Prompt template loader
â”‚       â”œâ”€â”€ tools-executor.ts   # Tool execution logic
â”‚       â”œâ”€â”€ prompts/
â”‚       â”‚   â”œâ”€â”€ system.txt      # System prompt template
â”‚       â”‚   â””â”€â”€ initial_prompt.txt # Initial prompt template
â”‚       â””â”€â”€ tools/              # Modular tool definitions
â”‚           â”œâ”€â”€ base-tool.ts    # Base interfaces
â”‚           â”œâ”€â”€ bash-tool.ts    # Shell execution
â”‚           â”œâ”€â”€ read-tool.ts    # File reading
â”‚           â”œâ”€â”€ write-tool.ts   # File creation
â”‚           â”œâ”€â”€ edit-tool.ts    # File editing
â”‚           â”œâ”€â”€ glob-tool.ts    # File search
â”‚           â”œâ”€â”€ grep-tool.ts    # Text search
â”‚           â”œâ”€â”€ web-search.ts   # Web search (Tavily)
â”‚           â””â”€â”€ extract-page-content.ts # Page extraction
â””â”€â”€ ui/                         # React frontend
    â”œâ”€â”€ App.tsx                 # Main component
    â”œâ”€â”€ components/             # UI components
    â””â”€â”€ store/                  # Zustand state management
```

## ğŸ” Data Storage

**Windows:** `C:\Users\YourName\AppData\Roaming\agent-cowork\`  
**macOS:** `~/Library/Application Support/agent-cowork/`  
**Linux:** `~/.config/agent-cowork/`

Files:
- `sessions.db` â€” SQLite database with chat history
- `api-settings.json` â€” API configuration
- `~/.agent-cowork/logs/` â€” request logs (debugging)

## âš ï¸ Troubleshooting

**Model doesn't see command results?**
- Ensure your model supports function calling
- Check DevTools (F12) â€” should see `tool` messages in console

**vLLM returns 404?**
- Check Base URL (system automatically adds `/v1`)
- Verify vLLM is running: `curl http://localhost:8000/health`

**Cyrillic showing as `ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½`?**
- Fixed in v0.0.3+

## ğŸ¤ Contributing

1. Fork the repository
2. Create a branch (`git checkout -b feature/amazing-feature`)
3. Commit (`git commit -m 'Add feature'`)
4. Push (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details

---

<div align="center">

**Made with â¤ï¸ by [Valerii Kovalskii](https://github.com/vakovalskii)**

Based on [DevAgentForge/Claude-Cowork](https://github.com/DevAgentForge/Claude-Cowork)

</div>
